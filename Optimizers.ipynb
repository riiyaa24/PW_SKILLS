{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the role of optimization algorithms in artificial neural networks? Why are they necessary?\n",
    "Optimization algorithms in artificial neural networks (ANNs) play a crucial role in training the model to minimize the error or loss function. Their primary role is to adjust the weights and biases of the network iteratively during training to minimize the difference between predicted outputs and actual targets. They are necessary because:\n",
    "\n",
    "ANNs are typically trained using large amounts of data, making manual adjustment of weights impractical.\n",
    "Optimization algorithms automate the process of finding optimal weights that minimize the error, improving the model's predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms of convergence speed and memory requirements.\n",
    "Gradient Descent: Gradient descent is a fundamental optimization algorithm used to minimize the loss function of a neural network by iteratively adjusting the weights in the direction of the negative gradient of the loss function with respect to the weights.\n",
    "\n",
    "Variants of Gradient Descent:\n",
    "\n",
    "Stochastic Gradient Descent (SGD): Updates weights using gradients computed on small random batches of data, which reduces memory requirements but introduces noisy updates.\n",
    "\n",
    "Mini-batch Gradient Descent: Combines aspects of both gradient descent and SGD by computing gradients over small batches of data. This balances memory usage and computational efficiency.\n",
    "\n",
    "Batch Gradient Descent: Computes gradients over the entire dataset in each iteration, ensuring precise updates but requiring large memory capacity.\n",
    "\n",
    "Differences and Tradeoffs:\n",
    "\n",
    "Convergence Speed: SGD and mini-batch GD typically converge faster due to more frequent weight updates, while batch GD may converge slower due to fewer updates.\n",
    "\n",
    "Memory Requirements: Batch GD requires more memory as it processes the entire dataset, while SGD and mini-batch GD are more memory-efficient but may suffer from noisy updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow convergence, local minima). How do modern optimizers address these challenges?\n",
    "Challenges with Traditional Gradient Descent:\n",
    "\n",
    "Slow Convergence: Batch GD can be slow, especially for large datasets, due to infrequent weight updates.\n",
    "\n",
    "Local Minima: Traditional GD methods can get stuck in local minima, leading to suboptimal solutions.\n",
    "\n",
    "Modern Optimizers:\n",
    "\n",
    "Adam (Adaptive Moment Estimation): Combines momentum and adaptive learning rates to accelerate convergence and handle sparse gradients.\n",
    "\n",
    "RMSprop (Root Mean Square Propagation): Adapts learning rates for each parameter based on the average of recent magnitudes of gradients, improving convergence in non-convex settings.\n",
    "\n",
    "AdaGrad (Adaptive Gradient Algorithm): Adjusts learning rates for each parameter based on the historical gradient information, effectively performing larger updates for infrequent parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do they impact convergence and model performance?\n",
    "Momentum: Momentum helps accelerate gradient descent by adding a fraction of the previous update vector to the current update. It smooths out the updates, allowing the optimizer to navigate through plateaus, small local minima, and saddle points more efficiently. Higher momentum values increase the convergence speed but may overshoot the global minimum.\n",
    "\n",
    "Learning Rate: Learning rate controls the step size in weight updates during training. A higher learning rate can speed up convergence initially but may cause instability or overshooting of the optimal solution. A lower learning rate results in more stable but slower convergence.\n",
    "\n",
    "Impact on Convergence and Performance:\n",
    "\n",
    "Momentum: Higher momentum values generally lead to faster convergence, especially in the presence of noise or sparse gradients.\n",
    "\n",
    "Learning Rate: Optimal learning rate tuning is critical; too high can lead to divergence, while too low can result in slow convergence. Techniques like learning rate schedules or adaptive methods (e.g., Adam) adjust learning rates dynamically to improve convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Explain the concept of Stochastic Gradient Descent (SGD) and its advantages compared to traditional gradient descent. Discuss its limitations and scenarios where it is most suitable.\n",
    "Stochastic Gradient Descent (SGD):\n",
    "\n",
    "Concept: SGD updates model weights using gradients computed on small random batches of data rather than the entire dataset. It introduces stochasticity into the optimization process, leading to faster updates and potentially quicker convergence compared to traditional batch gradient descent.\n",
    "Advantages:\n",
    "\n",
    "Faster Convergence: Updates are more frequent, leading to potentially faster convergence, especially in large datasets.\n",
    "Memory Efficiency: Only requires storing and processing small batches of data at a time, reducing memory usage.\n",
    "Regularization Effect: The noise introduced by stochasticity can act as a regularizer, preventing overfitting.\n",
    "Limitations:\n",
    "\n",
    "Noisy Updates: The stochastic nature can introduce noisy updates that may hinder convergence, especially early in training.\n",
    "Potential Oscillations: Small batch sizes can lead to oscillations in the training process.\n",
    "Sensitive to Learning Rate: Requires careful tuning of learning rate due to frequent updates.\n",
    "Suitable Scenarios:\n",
    "\n",
    "Large Datasets: Suitable when working with large datasets where batch gradient descent is computationally prohibitive.\n",
    "Online Learning: Useful in scenarios where new data arrives continuously and the model needs to be updated incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates. Discuss its benefits and potential drawbacks.\n",
    "Adam Optimizer:\n",
    "\n",
    "Concept: Adam (Adaptive Moment Estimation) combines the benefits of momentum and adaptive learning rates. It maintains a moving average of the gradients and the second moments of the gradients to adaptively adjust the learning rates for each parameter.\n",
    "Benefits:\n",
    "\n",
    "Adaptive Learning Rates: Adjusts learning rates for each parameter based on the magnitude of recent gradients, improving convergence in non-stationary environments.\n",
    "Efficient Momentum: Incorporates momentum to accelerate convergence, especially in the presence of sparse gradients.\n",
    "Robustness: Suitable for a wide range of problems and requires less tuning compared to traditional SGD.\n",
    "Drawbacks:\n",
    "\n",
    "Complexity: More complex than basic optimizers like SGD, which may increase computational overhead.\n",
    "Memory Usage: Maintaining additional statistics (moving averages) for each parameter increases memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning rates. Compare it with Adam and discuss their relative strengths and weaknesses.\n",
    "RMSprop Optimizer:\n",
    "\n",
    "Concept: RMSprop (Root Mean Square Propagation) addresses the challenges of adaptive learning rates by dividing the learning rate for a weight by a running average of the magnitudes of recent gradients for that weight.\n",
    "Comparison with Adam:\n",
    "\n",
    "Similarities: Both RMSprop and Adam use adaptive learning rates to accelerate convergence.\n",
    "Differences:\n",
    "Update Mechanism: Adam maintains both first and second moment estimates of gradients, whereas RMSprop only maintains a moving average of squared gradients.\n",
    "Adaptive Nature: Adam adapts learning rates more aggressively compared to RMSprop by incorporating momentum.\n",
    "Performance: Adam tends to perform better in scenarios with sparse gradients or noisy data due to its momentum term.\n",
    "Strengths and Weaknesses:\n",
    "\n",
    "RMSprop:\n",
    "\n",
    "Strengths: Effective in handling non-stationary objectives, suitable for recurrent neural networks (RNNs) due to reduced memory requirement.\n",
    "Weaknesses: May require more tuning of hyperparameters compared to Adam.\n",
    "Adam:\n",
    "\n",
    "Strengths: Combines momentum and adaptive learning rates effectively, robust performance across various scenarios.\n",
    "Weaknesses: Higher memory usage and computational complexity compared to simpler optimizers like RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Smita\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define a simple feedforward neural network\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create instances of the model with different optimizers\n",
    "model_sgd = create_model()\n",
    "model_adam = create_model()\n",
    "model_rmsprop = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 1.0904 - val_accuracy: 0.9082 - val_loss: 0.3213\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9095 - loss: 0.3124 - val_accuracy: 0.9202 - val_loss: 0.2673\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2530 - val_accuracy: 0.9375 - val_loss: 0.2171\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.2143 - val_accuracy: 0.9423 - val_loss: 0.1961\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1892 - val_accuracy: 0.9481 - val_loss: 0.1745\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1638 - val_accuracy: 0.9547 - val_loss: 0.1578\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1559 - val_accuracy: 0.9559 - val_loss: 0.1473\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1356 - val_accuracy: 0.9595 - val_loss: 0.1372\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.1275 - val_accuracy: 0.9621 - val_loss: 0.1243\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.1162 - val_accuracy: 0.9639 - val_loss: 0.1201\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.4541 - val_accuracy: 0.9618 - val_loss: 0.1186\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.1053 - val_accuracy: 0.9713 - val_loss: 0.0937\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0710 - val_accuracy: 0.9656 - val_loss: 0.1167\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0522 - val_accuracy: 0.9781 - val_loss: 0.0719\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0379 - val_accuracy: 0.9737 - val_loss: 0.0825\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0307 - val_accuracy: 0.9775 - val_loss: 0.0821\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0265 - val_accuracy: 0.9736 - val_loss: 0.0960\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0210 - val_accuracy: 0.9780 - val_loss: 0.0887\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0170 - val_accuracy: 0.9789 - val_loss: 0.0823\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0173 - val_accuracy: 0.9764 - val_loss: 0.0933\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.4217 - val_accuracy: 0.9626 - val_loss: 0.1233\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.1107 - val_accuracy: 0.9707 - val_loss: 0.1001\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9757 - loss: 0.0816 - val_accuracy: 0.9726 - val_loss: 0.0923\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0601 - val_accuracy: 0.9739 - val_loss: 0.0878\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0507 - val_accuracy: 0.9751 - val_loss: 0.0978\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0421 - val_accuracy: 0.9764 - val_loss: 0.0929\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0388 - val_accuracy: 0.9799 - val_loss: 0.0912\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0311 - val_accuracy: 0.9751 - val_loss: 0.1083\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0288 - val_accuracy: 0.9797 - val_loss: 0.0958\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0222 - val_accuracy: 0.9757 - val_loss: 0.1142\n"
     ]
    }
   ],
   "source": [
    "# Compile models with respective optimizers\n",
    "model_sgd.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_adam.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rmsprop.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train models\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history_sgd = model_sgd.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "history_adam = model_adam.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "history_rmsprop = model_rmsprop.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: Loss=0.1201, Accuracy=0.9639\n",
      "Adam: Loss=0.0933, Accuracy=0.9764\n",
      "RMSprop: Loss=0.1142, Accuracy=0.9757\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "loss_sgd, acc_sgd = model_sgd.evaluate(X_test, y_test, verbose=0)\n",
    "loss_adam, acc_adam = model_adam.evaluate(X_test, y_test, verbose=0)\n",
    "loss_rmsprop, acc_rmsprop = model_rmsprop.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"SGD: Loss={loss_sgd:.4f}, Accuracy={acc_sgd:.4f}\")\n",
    "print(f\"Adam: Loss={loss_adam:.4f}, Accuracy={acc_adam:.4f}\")\n",
    "print(f\"RMSprop: Loss={loss_rmsprop:.4f}, Accuracy={acc_rmsprop:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations and Tradeoffs\n",
    "When choosing the appropriate optimizer for a neural network architecture and task, several factors should be considered:\n",
    "\n",
    "Convergence Speed:\n",
    "\n",
    "SGD: Typically slower convergence due to noisy updates but can escape shallow local minima better.\n",
    "Adam and RMSprop: Faster convergence in many cases due to adaptive learning rates and momentum, which help in navigating through gradients more efficiently.\n",
    "Stability:\n",
    "\n",
    "SGD: Prone to oscillations, especially with larger learning rates.\n",
    "Adam and RMSprop: More stable due to adaptive learning rates, which adjust based on the gradient magnitudes.\n",
    "Generalization Performance:\n",
    "\n",
    "SGD: May generalize better in some cases due to its tendency to explore more diverse areas of the loss landscape.\n",
    "Adam and RMSprop: Can lead to quicker convergence but may overfit if learning rates or other hyperparameters are not properly tuned.\n",
    "Memory and Computational Requirements:\n",
    "\n",
    "SGD: Lower memory usage as it processes smaller batches but can be slower overall.\n",
    "Adam and RMSprop: Higher memory usage and computational complexity due to maintaining additional statistics for adaptive learning rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
